<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Introduction To Cloud and Distributed Systems - Part One - Hadi Sinaee</title><meta name=viewport content="width=device-width,initial-scale=1"><meta property=og:title content="Introduction To Cloud and Distributed Systems - Part One"><meta property=og:description content="TLDR This post is the first part of a series of posts about cloud and distributed systems. In this part, I try to introduce some of the fundamental concepts of distributed systems along with their properties — moreover, a gentle introduction to MapReduce, and Apache YARN architecture. I will discuss the definition of distributed systems. I am then introducing some of the essential features of it. After that, MapReduce is presented as a paradigm for writing a distributed application with the classic wordcount example."><meta property=og:type content=article><meta property=og:url content=https://hadisinaee.github.io/posts/distributed-systems-part-one/><meta property=article:published_time content=2019-08-21T00:34:53+04:30><meta property=article:modified_time content=2019-08-21T00:34:53+04:30><meta name=twitter:card content=summary><meta name=twitter:title content="Introduction To Cloud and Distributed Systems - Part One"><meta name=twitter:description content="TLDR This post is the first part of a series of posts about cloud and distributed systems. In this part, I try to introduce some of the fundamental concepts of distributed systems along with their properties — moreover, a gentle introduction to MapReduce, and Apache YARN architecture. I will discuss the definition of distributed systems. I am then introducing some of the essential features of it. After that, MapReduce is presented as a paradigm for writing a distributed application with the classic wordcount example."><link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel=stylesheet><link rel=stylesheet type=text/css media=screen href=/css/normalize.css><link rel=stylesheet type=text/css media=screen href=/css/main.css><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src=/js/main.js></script></head><body><div class="container wrapper post"><div class=header><h1 class=site-title>Hadi Sinaee</h1><div class=site-description><h2>Entrepreneur, In Love With Data!</h2><nav class="nav social"><ul class=flat><a href=https://github.com/hadisinaee title=Github><i data-feather=github></i></a><a href=https://twitter.com/hadisinaee title=Twitter><i data-feather=twitter></i></a><a href=mailto:myname.at.ostadkar.pro title=Email><i data-feather=mail></i></a><a href=/index.xml title=RSS><i data-feather=rss></i></a></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Home</a></li><li><a href=/posts>All posts</a></li><li><a href=/about>About</a></li><li><a href=/tags>Tags</a></li></ul></nav></div><div class=post-header><h1 class=title>Introduction To Cloud and Distributed Systems - Part One</h1><div class=meta>Posted at &mdash; Aug 21, 2019 | Reading Time: 8 min</div></div><div class=markdown><h3 id=tldr>TLDR</h3><p>This post is the first part of a series of posts about cloud and distributed systems. In this part, I try to introduce some of the fundamental concepts of distributed systems along with their properties — moreover, a gentle introduction to MapReduce, and Apache YARN architecture. I will discuss the definition of distributed systems. I am then introducing some of the essential features of it. After that, MapReduce is presented as a paradigm for writing a distributed application with the classic wordcount example. In the end, Apache YARN and its high-level architecture discussed alongside with failure detection and recovery in that framework.</p><p><em>P.S: this series of post is mostly based on a course by Professor Indranil Gupta at UIUC at <a href=https://www.coursera.org/learn/cloud-computing/home/welcome>coursera</a>.</em></p><h3 id=introduction>Introduction</h3><p>A distributed environment is an environment that several machines, in a data center or a network, are providing services for internal or external consumption. The overall architecture follows a Server-Client pattern in which while some machines are providing services, others are consuming these services. These communications happen in multiple forms; it can be server to server, client to client(like P2P networks), and the client to server. These types of communications between servers and clients create a distributed system with a collection of machines.</p><p>A distributed system posses the following features:</p><ol><li><strong>Massive Scale</strong>: it consists of a cluster of machines which can consist of hundreds or thousands of them.</li><li><strong>On-Demanded</strong>: the services provided by the machines, have to be accessible whenever an entity, clients or servers, demand for it.</li><li><strong>Data-Intensive</strong>: due to the vast amount of data, there are many machines to store and process such data.</li><li><strong>A New Paradigm For Programming</strong>: there should be a way for a programmer to implement such systems.</li></ol><p>The core concepts of cloud systems have been borrowed from distributed systems. The cloud is a particular type of distributed systems. Therefore, the knowledge of distributed systems is essential for understanding cloud systems.</p><p>Let&rsquo;s start with the definition of distributed systems. <em>Indranil Gupta</em>, professor of UIUC, gives this definition:</p><blockquote><p>A distributed system is a collection of entities, each of which is <strong>autonomous</strong>, <strong>programmable</strong>, <strong>asynchronous</strong> and <strong>failure-prone</strong>, and which communicate through an <strong>unreliable communication medium</strong>.</p></blockquote><p>Let&rsquo;s dig deeper into each fundamental element of this definition.</p><ul><li><strong>Entity</strong>: it is a process that is running on a device, such as a PC or a Laptop.</li><li><strong>Autonomous</strong>: if an entity(a process) left alone in a device, it could be run without any problem. In simple terms, for an entity to run, there is no need for anything else, just an environment that is compatible with the entity.</li><li><strong>Programmable</strong>: these entities have to be programmed by a programmer. It is essential since, according to the autonomous feature, these entities have to depleted with any human intervention for running.</li><li><strong>Asynchronous</strong>: these entities are running with their clock; independent from one another. Notice that this feature is in contrast to the parallel systems which they have a synchronized clock.</li><li><strong>Failure-prone</strong>: The entities may fail during their execution. However, they could recover from that state and continue.</li><li><strong>Unreliable Communication Medium</strong>: messages which are sent over a communication medium, such as wire, maybe dropped; resulting in an unreliable medium for communication between entities.</li></ul><p><img src=/images/distributed-systems-part-one/distributed_system.png alt=distributed_system-01></p><p>We mentioned that entities in a distributed system have to programmable. Therefore, there should be tools or frameworks to develop applications for a distributed system. One way to program such systems is by using the <code>MapReduce</code> paradigm. It is a programming model and processing technique for writing a distributed application.</p><h3 id=mapreduce><code>MapReduce</code></h3><p><code>MapReduce</code> is a programming paradigm which borrowed its concepts from functional programming. By paradigm, it means that you have to think in a specific way to implement your task using <code>MapReduce</code>. It consists of two phases as its name implies; Map and Reduce.</p><p>The Map is a function or an operator which creates key-value pairs of a given data. These outputs are considered as intermediate results for the next phase, the Reduce.</p><p>The Reduce is also a function that consumes the outputs of the Map phase and creates the final result. The Reduce function is called with intermediates key-value pairs which have a shared key.</p><p>Let&rsquo;s start with wordcount problem, which is a classic example of <code>MapReduce</code>. In this problem, you want to count the number of words in a large text. Let&rsquo;s have the following text file as the input to our <code>MapReduce</code> program.</p><div class=highlight><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4># sample text file
Hadi Hadi hello I hope you you you are doing well.</pre></div><p>In the paradigm of <code>MapReduce</code>, we have to define two phases for this problem, Map and Reduce. Outputs of Map phase are pairs of the form (word, 1). In our example, it is:</p><div class=highlight><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#666>(</span>hello, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>Hadi, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>Hadi, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>I, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>hope, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>you, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>you, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>you, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>are, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>doing, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>well, <span style=color:#40a070>1</span><span style=color:#666>)</span></code></pre></div><p>In the Reduce phase, it merges the intermediate key-value pairs from the previous step by assigning each pair with the same key to a Reducer. One way to do this assignment is to use a hash function on the key over the key-value pairs. In our example, the outputs of Reduce are:</p><div class=highlight><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#666>(</span>hello, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>Hadi, <span style=color:#40a070>2</span><span style=color:#666>)</span>
<span style=color:#666>(</span>I, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>hope, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>you, <span style=color:#40a070>3</span><span style=color:#666>)</span>
<span style=color:#666>(</span>doing, <span style=color:#40a070>1</span><span style=color:#666>)</span>
<span style=color:#666>(</span>well, <span style=color:#40a070>1</span><span style=color:#666>)</span></code></pre></div><p>Our example can be illustrated in the following image.</p><p><img src=/images/distributed-systems-part-one/map_reduce_example.png alt=distributed_system-02></p><p>We can discuss the <code>MapReduce</code> from two different perspectives. One from the user, which is the programmer, and the second one is the framework, the way internally it is working. The following picture can show a high-level overview of it.</p><h3 id=user-perspective>User Perspective</h3><p>A user writes two types of functions, one type for Map tasks and another for Reduce tasks. The problem may consist of several chains of Map and Reduce phases; however, in the end, the user is always concerning about writing two forms of functions.</p><h3 id=internal-perspective>Internal Perspective</h3><p>The internal process of <code>MapReduce</code> deals with parallelizing Map and Reduce tasks. Because Map tasks are independent of each other, they can be parallelized internally without any higher-level consideration for the programmer. The same reason goes for Reduce tasks, and they can be parallelized without any further consideration of the programmer.</p><p>For both Map and Reduce tasks, since it is a distributed environment, there has to be a distributed filesystem for reading and writing data, such as <code>HDFS</code> or <code>GFS</code>. This distributed file system is running in the same servers as Map and Reduce tasks are running. The main task of these distributed file systems is to keep multiple replications of data to ensure data availability and fault-tolerance. It is crucial to know that the output of Map tasks is written in the local file system, such as ext4 in Linux. Therefore, the Reduce task reads the required Map output from the remote file system. After the Reduce tasks completed, then the outputs are written in the distributed file system. Based on these, how Map and Reduce tasks are appropriately scheduled to achieve high performance?</p><p>In scheduling Maps, the Map tasks tried to be mapped to servers where the data they need for their input is available. At the second level, the Map tasks are mapped in the same rack as the data it needed resides in there. At last, it will be scheduled wherever possible. This hierarchy is designed so that the network bandwidth usage becomes low as much as possible.</p><p>Besides, the internal process has to ensure that all Map tasks are completed before any Reduce task starts. We call this constrain a barrier between Map and Reduce phase. Therefore, Reduce tasks cannot start until all Map tasks finished.</p><h3 id=apache-hadoop-yarn>Apache Hadoop <code>YARN</code></h3><p><a href=https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html>Apache Hadoop <code>YARN</code></a> is a framework which lets you write a distributed application using the <code>MapReduce</code> paradigm. In the following, I discuss a high-level introduction about <code>YARN</code> and <code>MapReduce</code>.</p><p>The <code>YARN</code> is both a scheduler and resource manager for assigning tasks to a collection of containers, which it can only be a process with a specific amount of CPUs and some amount of memories. It has three main components:<em>Global Resource Manager(RM)</em>, <em>Per-Server node manager(NM)</em> and <em>Per-Application Application Master(AM)</em>. The following shows the mentioned components and their relationships in a higher-level.</p><p><img src=https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif alt=yarn-architecture-high-level></p><p>RM do the scheduling for tasks. NM is responsible for resource management for each server. AM is responsible for failure detection of tasks to reschedule it in another server.</p><h3 id=how-mapreduce-deals-with-failures>How <code>MapReduce</code> deals with failures?</h3><p>Failure is the norm rather than the exception in the distributed systems. It means that you have to have a plan for such incidents since they are probable. <code>YARN</code> deals with this norm using different approaches. Before that, we have to know what types of failures system is going to experience. Then, what is the approach for failure detection and a possible recovery strategy?</p><p>NM sends heartbeats to the RM. If there is a failure, then RM tells all affected AMs about it to send rescheduling request. Also, NM keeps tracks of running tasks to find out about their status. If any task fails, such as run-time errors, it marks the task as idle or tells either the AM or RM about it to reschedule. Moreover, AM sends heartbeats to RM. In any case that the AM fails, the RM up another AM and sync it with the tasks it was running. RM, itself, can encounter with failure; in this case, there should be another RM in standby mode to be in place.</p><h4 id=stragglers-and-speculative-execution>Stragglers And Speculative Execution</h4><p>There might be some slow nodes, due to the shortage of memory or CPU, in the cluster; they are called <strong>Stragglers</strong>. As mentioned before, no Reduce task starts until all Map tasks complete. Therefore, the slowest machine can slow down the entire process of completing the job. To solve it, the slowest task is replicated in a different server to be run. The slowest task and its replica are in the race for completion. Whichever finishes the job sooner the other one is killed. This approach is known as <strong>Speculative Execution</strong>.</p></div><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")
return;var dsq=document.createElement('script');dsq.type='text/javascript';dsq.async=true;var disqus_shortname='blog';dsq.src='//'+disqus_shortname+'.disqus.com/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript><a href=http://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="footer wrapper"><nav class=nav><div><a href=https://github.com/vividvilla/ezhil>Ezhil theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></nav></div><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-126465782-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script>feather.replace()</script></body></html>